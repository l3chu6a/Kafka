{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b96e222a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-t TIME | -n NUMBER] [-o OUTPUT] [-v]\n",
      "                             [-w WORKERS]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --f=c:\\Users\\sebas\\AppData\\Roaming\\jupyter\\runtime\\kernel-v32828020c8c4af5bb4513473fe337ed0f83babdd0.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Proyectos\\Kafka\\kafka\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3675: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from atproto import FirehoseSubscribeReposClient, parse_subscribe_repos_message, CAR, IdResolver, DidInMemoryCache\n",
    "import json\n",
    "import time\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "import multiprocessing\n",
    "import sys\n",
    "import signal\n",
    "\n",
    "def worker_process(queue, output_file, verbose, post_count, lock, stop_event):\n",
    "    resolver = IdResolver(cache=DidInMemoryCache())\n",
    "    while not stop_event.is_set():\n",
    "        try:\n",
    "            message = queue.get(timeout=1)\n",
    "            process_message(message, resolver, output_file, verbose, post_count, lock)\n",
    "        except multiprocessing.queues.Empty:\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"Worker error: {e}\")\n",
    "\n",
    "def client_process(queue, stop_event):\n",
    "    client = FirehoseSubscribeReposClient()\n",
    "    \n",
    "    def message_handler(message):\n",
    "        if stop_event.is_set():\n",
    "            client.stop()\n",
    "            return\n",
    "        queue.put(message)\n",
    "    \n",
    "    try:\n",
    "        client.start(message_handler)\n",
    "    except Exception as e:\n",
    "        if not stop_event.is_set():\n",
    "            print(f\"Client process error: {e}\")\n",
    "\n",
    "def process_message(message, resolver, output_file, verbose, post_count, lock):\n",
    "    \"\"\"Process a single message from the firehose\"\"\"\n",
    "    try:\n",
    "        commit = parse_subscribe_repos_message(message)\n",
    "        if not hasattr(commit, 'ops'):\n",
    "            return\n",
    "\n",
    "        for op in commit.ops:\n",
    "            if op.action == 'create' and op.path.startswith('app.bsky.feed.post/'):\n",
    "                _process_post(commit, op, resolver, output_file, verbose, post_count, lock)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing message: {e}\")\n",
    "\n",
    "def _process_post(commit, op, resolver, output_file, verbose, post_count, lock):\n",
    "    \"\"\"Process a single post operation\"\"\"\n",
    "    try:\n",
    "        author_handle = _resolve_author_handle(commit.repo, resolver)\n",
    "        car = CAR.from_bytes(commit.blocks)\n",
    "        for record in car.blocks.values():\n",
    "            if isinstance(record, dict) and record.get('$type') == 'app.bsky.feed.post':\n",
    "                post_data = _extract_post_data(record, commit.repo, op.path, author_handle)\n",
    "                _save_post_data(post_data, output_file, verbose, post_count, lock)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing record: {e}\")\n",
    "\n",
    "def _resolve_author_handle(repo, resolver):\n",
    "    \"\"\"Resolve the author handle from the DID\"\"\"\n",
    "    try:\n",
    "        resolved_info = resolver.did.resolve(repo)\n",
    "        return resolved_info.also_known_as[0].split('at://')[1] if resolved_info.also_known_as else repo\n",
    "    except Exception as e:\n",
    "        print(f\"Could not resolve handle for {repo}: {e}\")\n",
    "        return repo  # Fallback to DID\n",
    "\n",
    "def _extract_post_data(record, repo, path, author_handle):\n",
    "    \"\"\"Extract post data from a record\"\"\"\n",
    "    has_images = _check_for_images(record)\n",
    "    reply_to = _get_reply_to(record)\n",
    "    return {\n",
    "        'text': record.get('text', ''),\n",
    "        'created_at': record.get('createdAt', ''),\n",
    "        'author': author_handle,\n",
    "        'uri': f'at://{repo}/{path}',\n",
    "        'has_images': has_images,\n",
    "        'reply_to': reply_to\n",
    "    }\n",
    "\n",
    "def _check_for_images(record):\n",
    "    \"\"\"Check if the post has images\"\"\"\n",
    "    embed = record.get('embed', {})\n",
    "    return (\n",
    "        embed.get('$type') == 'app.bsky.embed.images' or\n",
    "        (embed.get('$type') == 'app.bsky.embed.external' and 'thumb' in embed)\n",
    "    )\n",
    "\n",
    "def _get_reply_to(record):\n",
    "    \"\"\"Get the URI of the post being replied to\"\"\"\n",
    "    reply_ref = record.get('reply', {})\n",
    "    return reply_ref.get('parent', {}).get('uri')\n",
    "\n",
    "def _save_post_data(post_data, output_file, verbose, post_count, lock):\n",
    "    \"\"\"Save post data to the output file\"\"\"\n",
    "    with lock:\n",
    "        with open(output_file, 'a') as f:\n",
    "            json.dump(post_data, f)\n",
    "            f.write('\\n')\n",
    "    with post_count.get_lock():\n",
    "        post_count.value += 1\n",
    "    if verbose:\n",
    "        print(f\"Saved post by @{post_data['author']}: {post_data['text'][:50]}...\")\n",
    "\n",
    "class FirehoseScraper:\n",
    "    def __init__(self, output_file=\"bluesky_posts.jsonl\", verbose=False, num_workers=4):\n",
    "        self.output_file = output_file\n",
    "        self.post_count = multiprocessing.Value('i', 0)  # Shared integer\n",
    "        self.start_time = None\n",
    "        self.cache = DidInMemoryCache() \n",
    "        self.resolver = IdResolver(cache=self.cache)\n",
    "        self.verbose = verbose\n",
    "        self.queue = multiprocessing.Queue()\n",
    "        self.num_workers = num_workers\n",
    "        self.workers = []\n",
    "        self.stop_event = multiprocessing.Event()\n",
    "        self.lock = multiprocessing.Lock()  # For thread-safe file writing\n",
    "        self.client_proc = None  # Renamed to avoid conflict\n",
    "\n",
    "    def start_collection(self, duration_seconds=None, post_limit=None):\n",
    "        \"\"\"Start collecting posts from the firehose\"\"\"\n",
    "        print(f\"Starting collection{f' for {post_limit} posts' if post_limit else ''}...\")\n",
    "        self.start_time = time.time()\n",
    "        end_time = self.start_time + duration_seconds if duration_seconds else None\n",
    "\n",
    "        # Start worker processes\n",
    "        for _ in range(self.num_workers):\n",
    "            p = multiprocessing.Process(\n",
    "                target=worker_process,\n",
    "                args=(\n",
    "                    self.queue, \n",
    "                    self.output_file, \n",
    "                    self.verbose, \n",
    "                    self.post_count, \n",
    "                    self.lock, \n",
    "                    self.stop_event\n",
    "                )\n",
    "            )\n",
    "            p.start()\n",
    "            self.workers.append(p)\n",
    "\n",
    "\n",
    "        # Handle KeyboardInterrupt in the main process\n",
    "        def signal_handler(sig, frame):\n",
    "            print(\"\\nCollection stopped by user.\")\n",
    "            self._stop_collection()\n",
    "            sys.exit(0)\n",
    "\n",
    "        signal.signal(signal.SIGINT, signal_handler)\n",
    "\n",
    "        while True:\n",
    "            # Start the client in a separate process\n",
    "            self.client_proc = multiprocessing.Process(\n",
    "                target=client_process,\n",
    "                args=(self.queue, self.stop_event)\n",
    "            )\n",
    "            self.client_proc.start()\n",
    "\n",
    "            # Monitor the collection\n",
    "            try:\n",
    "                while True:\n",
    "                    if self.stop_event.is_set():\n",
    "                        break\n",
    "                    if duration_seconds and time.time() > end_time:\n",
    "                        print(\"\\nTime limit reached.\")\n",
    "                        self._stop_collection()\n",
    "                        break\n",
    "                    elif post_limit and self.post_count.value >= post_limit:\n",
    "                        print(\"\\nPost limit reached.\")\n",
    "                        self._stop_collection()\n",
    "                        break\n",
    "                    if not self.client_proc.is_alive():\n",
    "                        if not self.stop_event.is_set():\n",
    "                            # Client process exited unexpectedly\n",
    "                            print(\"\\nClient process exited unexpectedly.\")\n",
    "                            self._stop_collection()\n",
    "\n",
    "                            break\n",
    "                        else:\n",
    "                            # Stop event is set; exit the loop\n",
    "                            break\n",
    "                    time.sleep(1)\n",
    "                else:\n",
    "                    # If the collection completed successfully, break out of the retry loop\n",
    "                    break\n",
    "                if self.stop_event.is_set():\n",
    "                    break\n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\nCollection interrupted by user.\")\n",
    "                self._stop_collection()\n",
    "                break\n",
    "            except Exception as e:\n",
    "                error_details = f\"{type(e).__name__}: {str(e)}\" if str(e) else f\"{type(e).__name__}\"\n",
    "                print(f\"\\nConnection error: {error_details}\")\n",
    "\n",
    "        self._stop_collection()\n",
    "\n",
    "    def _stop_collection(self):\n",
    "        \"\"\"Stop the collection and print summary\"\"\"\n",
    "        if not self.stop_event.is_set():\n",
    "            self.stop_event.set()\n",
    "\n",
    "        if self.client_proc and self.client_proc.is_alive():\n",
    "            self.client_proc.terminate()\n",
    "            self.client_proc.join()\n",
    "\n",
    "        # Wait for all worker processes to finish\n",
    "        for p in self.workers:\n",
    "            if p.is_alive():\n",
    "                p.terminate()\n",
    "            p.join()\n",
    "\n",
    "        elapsed = time.time() - self.start_time if self.start_time else 0\n",
    "        rate = self.post_count.value / elapsed if elapsed > 0 else 0\n",
    "        print(\"\\nCollection complete!\")\n",
    "        print(f\"Collected {self.post_count.value} posts in {elapsed:.2f} seconds\")\n",
    "        print(f\"Average rate: {rate:.1f} posts/sec\")\n",
    "        print(f\"Output saved to: {self.output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Collect posts from the Bluesky firehose')\n",
    "    group = parser.add_mutually_exclusive_group()\n",
    "    group.add_argument('-t', '--time', type=int, help='Collection duration in seconds')\n",
    "    group.add_argument('-n', '--number', type=int, help='Number of posts to collect')\n",
    "    parser.add_argument('-o', '--output', type=str, \n",
    "                        default=f\"bluesky_posts_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jsonl\",\n",
    "                        help='Output file path (default: bluesky_posts_TIMESTAMP.jsonl)')\n",
    "    parser.add_argument('-v', '--verbose', action='store_true',\n",
    "                        help='Print each post as it is collected')\n",
    "    parser.add_argument('-w', '--workers', type=int, default=4,\n",
    "                        help='Number of worker processes (default: 4)')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    archiver = FirehoseScraper(output_file=args.output, verbose=args.verbose, num_workers=args.workers)\n",
    "    archiver.start_collection(duration_seconds=args.time, post_limit=args.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412d25c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kafka",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
